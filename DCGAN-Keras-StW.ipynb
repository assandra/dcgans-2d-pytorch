{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: failed with initial frozen solve. Retrying with flexible solve.\n",
      "Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: / "
     ]
    }
   ],
   "source": [
    "conda install -c anaconda tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install -c anaconda cudatoolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "from numpy import expand_dims, zeros, ones, vstack, add\n",
    "from numpy.random import randn, randint, normal\n",
    "from matplotlib import pyplot\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Conv2D, Conv2DTranspose, LeakyReLU, Dropout, BatchNormalization, ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2D Scan The World busts dataset: \n",
    "dataset_name = \"scan-the-world-busts-images\"\n",
    "dataroot = \"/home/a/Projects/dggan-pytorch-2d-images/data/scan-the-world-busts-images/\"\n",
    "\n",
    "# Model input dimensions\n",
    "img_rows = 64\n",
    "img_cols = 64\n",
    "channels = 3\n",
    "\n",
    "# Input image dimensions\n",
    "img_shape = (img_rows, img_cols, channels)\n",
    "\n",
    "# Size of the noise vector, used as input to the Generator\n",
    "z_dim = 100\n",
    "\n",
    "# Number of data points used in each training loop\n",
    "batch_size = 128\n",
    "\n",
    "# Number of training epochs\n",
    "num_epochs = 150\n",
    "\n",
    "# Learning rate for training\n",
    "learning_rate = 0.0002\n",
    "\n",
    "# Hyperparameter for Adam optimizers\n",
    "beta_1 = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1291 files belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = image_dataset_from_directory(\n",
    "    dataroot, label_mode=None, shuffle=True, seed=999, image_size=(img_rows, img_cols), batch_size=batch_size\n",
    ")\n",
    "dataset = dataset.map(lambda x: x / 255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualise dataset\n",
    "for x in dataset:\n",
    "    pyplot.axis(\"off\")\n",
    "    pyplot.imshow((x.numpy() * 255).astype(\"int32\")[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator model\n",
    "def define_discriminator(in_shape=img_shape):\n",
    "    model = Sequential([\n",
    "          Input(shape=(64, 64, 3)),\n",
    "          Conv2D(64, kernel_size=4, strides=2, padding=\"same\"),\n",
    "          LeakyReLU(alpha=0.2),\n",
    "          Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),\n",
    "          BatchNormalization(),\n",
    "          LeakyReLU(alpha=0.2),\n",
    "          Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),\n",
    "          BatchNormalization(),\n",
    "          LeakyReLU(alpha=0.2),\n",
    "          Flatten(),\n",
    "          Dropout(0.2),\n",
    "          Dense(1, activation=\"sigmoid\"),\n",
    "      ],\n",
    "      name=\"discriminator\",\n",
    "  )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Discriminator summary\n",
    "# discriminator = define_discriminator((64,64,3))\n",
    "\n",
    "# discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator model\n",
    "def define_generator(z_dim):\n",
    "    model = Sequential([\n",
    "         Input(shape=(z_dim,)),\n",
    "         Dense(8 * 8 * 128),\n",
    "         Reshape((8, 8, 128)),\n",
    "         Conv2DTranspose(128, kernel_size=4, strides=2, padding=\"same\"),\n",
    "         BatchNormalization(),\n",
    "         LeakyReLU(alpha=0.2),\n",
    "         Conv2DTranspose(256, kernel_size=4, strides=2, padding=\"same\"),\n",
    "         BatchNormalization(),\n",
    "         LeakyReLU(alpha=0.2),\n",
    "         Conv2DTranspose(512, kernel_size=4, strides=2, padding=\"same\"),\n",
    "         BatchNormalization(),\n",
    "         LeakyReLU(alpha=0.2),\n",
    "         Conv2D(3, kernel_size=5, padding=\"same\", activation=\"sigmoid\"),\n",
    "    ],\n",
    "    name=\"generator\",\n",
    ")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator summary\n",
    "# generator = define_generator(z_dim)\n",
    "\n",
    "# generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GAN model\n",
    "def define_gan(generator, discriminator):\n",
    "    discriminator.trainable = False\n",
    "    model = Sequential()\n",
    "    model.add(generator)\n",
    "    model.add(discriminator)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Model: \"discriminator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 32, 32, 64)        3136      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)   (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 16, 16, 128)       131200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)   (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 8, 8, 128)         262272    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 8193      \n",
      "=================================================================\n",
      "Total params: 405,825\n",
      "Trainable params: 405,313\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Model: \"generator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 8192)              827392    \n",
      "_________________________________________________________________\n",
      "reshape_3 (Reshape)          (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_9 (Conv2DTr (None, 16, 16, 128)       262272    \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)   (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_10 (Conv2DT (None, 32, 32, 256)       524544    \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 32, 32, 256)       1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_22 (LeakyReLU)   (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_11 (Conv2DT (None, 64, 64, 512)       2097664   \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 64, 64, 512)       2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_23 (LeakyReLU)   (None, 64, 64, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 64, 64, 3)         38403     \n",
      "=================================================================\n",
      "Total params: 3,753,859\n",
      "Trainable params: 3,752,067\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build and compile the Discriminator\n",
    "discriminator = define_discriminator(img_shape)\n",
    "discriminator.compile(loss='binary_crossentropy',\n",
    "                      optimizer=Adam(learning_rate=learning_rate, beta_1=beta_1),\n",
    "                      metrics=['accuracy'])\n",
    "discriminator.summary()\n",
    "\n",
    "# Build the Generator\n",
    "generator = define_generator(z_dim)\n",
    "generator.summary()\n",
    "\n",
    "# Keep Discriminator’s parameters constant for Generator training\n",
    "discriminator.trainable = False\n",
    "\n",
    "# Build and compile GAN model with fixed Discriminator to train the Generator\n",
    "gan = define_gan(generator, discriminator)\n",
    "gan.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=learning_rate, beta_1=beta_1))\n",
    "\n",
    "# GAN summary\n",
    "# gan.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_images(generator, image_grid_rows=4, image_grid_columns=4):\n",
    "\n",
    "    # Generate images from random noise\n",
    "    z = np.random.normal(0, 1, (image_grid_rows * image_grid_columns, z_dim))\n",
    "    gen_imgs = generator.predict(z)\n",
    "\n",
    "    # Rescale image pixel values to [0, 1]\n",
    "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "    # Set image grid\n",
    "    fig, axs = plt.subplots(image_grid_rows,\n",
    "                            image_grid_columns,\n",
    "                            figsize=(4, 4),\n",
    "                            sharey=True,\n",
    "                            sharex=True)\n",
    "\n",
    "    cnt = 0\n",
    "    for i in range(image_grid_rows):\n",
    "        for j in range(image_grid_columns):\n",
    "            # Output a grid of images\n",
    "            axs[i, j].imshow(gen_imgs[cnt, :, :, 0])\n",
    "            axs[i, j].axis('off')\n",
    "            cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop \n",
    "\n",
    "# List of training values\n",
    "img_list = []\n",
    "g_losses = []\n",
    "d_losses = []\n",
    "d_accuracies = []\n",
    "\n",
    "# Labels for images\n",
    "y_real = ones((batch_size, 1))\n",
    "y_fake = zeros((batch_size, 1))\n",
    "\n",
    "iterations = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, imgs in enumerate(dataset):\n",
    "\n",
    "        # -------------------------\n",
    "        #  Train the Discriminator\n",
    "        # -------------------------\n",
    "\n",
    "        # Generate a batch of fake images\n",
    "        z = normal(0, 1, (batch_size, z_dim))\n",
    "        gen_imgs = generator.predict(z)\n",
    "\n",
    "        # Train the discriminaor on the generated images\n",
    "        d_loss_real = discriminator.train_on_batch(imgs, y_real)\n",
    "        d_loss_fake = discriminator.train_on_batch(gen_imgs, y_fake)\n",
    "\n",
    "        d_loss, d_accuracy = 0.5 * add(d_loss_real, d_loss_fake)\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train the Generator\n",
    "        # ---------------------\n",
    "\n",
    "        # Generate a batch of fake images\n",
    "        z = normal(0, 1, (batch_size, z_dim))\n",
    "        gen_imgs = generator.predict(z)\n",
    "\n",
    "\n",
    "        # Train the generator via the gan model - note inverted labels\n",
    "        g_loss = gan.train_on_batch(z, y_real)\n",
    "\n",
    "        # Output training stats\n",
    "        if i % 50 == 0:\n",
    "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_D_fake: %.4f\\tLoss_D_real: %.4f\\tLoss_G: %.4f\\tD_acc: %.4f'\n",
    "                  % (epoch, num_of_epochs, i, len(dataset), d_loss, d_loss_fake, d_loss_real, g_loss, d_accuracy))\n",
    "\n",
    "        # Save losses for plotting later\n",
    "        g_losses.append(g_loss)\n",
    "        d_losses.append(d_loss)\n",
    "        d_fake_losses.append(d_loss_fake)\n",
    "        d_real_losses.append(d_loss_real)\n",
    "        d_accuracies.append(d_accuracy)\n",
    "\n",
    "        # Check how the generator is doing by predicting G's output\n",
    "        if (iterations % 500 == 0) or ((epoch == num_epochs-1) and (i == len(dataloader)-1)):\n",
    "            sample_images(generator)\n",
    "\n",
    "        iterations += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "plt.plot(G_losses,label=\"G\")\n",
    "plt.plot(D_losses,label=\"D\")\n",
    "plt.plot(D_fake_losses,label=\"D_fake\")\n",
    "plt.plot(D_real_losses,label=\"D_real\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(path,\"generator_discriminator_losses.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.title(\"Discriminator Accuracy During Training\")\n",
    "plt.plot(D_x_acc,label=\"D_acc\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(path,\"discriminator_accuracy.png\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
